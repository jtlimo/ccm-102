@inproceedings{Aissou2021,
  author={Aissou, Ghilas and Slimane, Hadjar Ould and Benouadah, Selma and Kaabouch, Naima},
  booktitle={2021 IEEE 12th Annual Ubiquitous Computing, Electronics $\&$ Mobile Communication Conference (UEMCON)}, 
  title={Tree-based Supervised Machine Learning Models For Detecting GPS Spoofing Attacks on UAS}, 
  year={2021},
  volume={},
  number={},
  pages={0649-0653},
  keywords={Radio frequency;Navigation;Memory management;Security;Random forests;Global Positioning System;Software radio;UAS;GPS Spoofing Attacks;Detection Tech-niques;Machine Learning},
  doi={10.1109/UEMCON53757.2021.9666744}}

@inproceedings{capitanFrameworkHandleThreats2019,
title = {A Framework to Handle Threats for {{UAS}} Operating in the {{U-space}}},
booktitle = {2019 {{Workshop}} on {{Research}}, {{Education}} and {{Development}}
of {{Unmanned Aerial Systems}} ({{RED UAS}})},
author = {Capit{\'a}n, Carlos and Casta{\~n}o, {\'A}ngel R. and Capit{\'a}n, Jes{\'u}s
and Ollero, An{\'i}bal},
year = {2019},
pages = {1--8},
doi = {10.1109/REDUAS47371.2019.8999673},
urldate = {2025-07-23}}

@inproceedings{elalamiDroneDefGANtGenerativeAIBased2024,
title = {{{DroneDefGANt}}: {{A Generative AI-Based Approach}} for {{Detecting UAS
Attacks}} and {{Faults}}},
shorttitle = {{{DroneDefGANt}}},
booktitle = {{{ICC}} 2024 - {{IEEE International Conference}} on
{{Communications}}},
author = {{El alami}, Hassan and Rawat, Danda B.},
year = {2024},
pages = {1933--1938},
issn = {1938-1883},
doi = {10.1109/ICC51166.2024.10622524},
urldate = {2025-07-23}}

@inproceedings{isleyenGPSSpoofingDetection2024,
title = {{{GPS Spoofing Detection}} on {{Autonomous Vehicles}} with {{XGBoost}}},
booktitle = {2024 9th {{International Conference}} on {{Computer Science}} and
{{Engineering}} ({{UBMK}})},
author = {{\.I}{\c s}leyen, Emre and Bahtiyar, {\c S}erif},
year = {2024},
pages = {500--505},
issn = {2521-1641},
doi = {10.1109/UBMK63289.2024.10773593},
urldate = {2025-07-23},
langid = {american}}

@article{nayfehMachineLearningModeling2023,
title = {Machine {{Learning Modeling}} of {{GPS Features}} with {{Applications}} to
{{UAV Location Spoofing Detection}} and {{Classification}}},
author = {Nayfeh, Mohammad and Li, Yuchen and Shamaileh, Khair Al and
Devabhaktuni, Vijay and Kaabouch, Naima},
year = {2023},
journal = {Computers \& Security},
volume = {126},
pages = {103085},
publisher = {Elsevier BV},
issn = {0167-4048},
doi = {10.1016/j.cose.2022.103085},
copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
langid = {english}}

@article{sheGPSSpoofingAttack2024,
title = {{{GPS Spoofing Attack Recognition}} for {{UAVs With Limited Samples}}},
author = {She, Dingchen and Wang, Wei and Yin, Zhisheng and Wang, Jiaqi and
Shan, Haifeng},
year = {2024},
journal = {IEEE Internet of Things Journal},
volume = {12},
number = {1},
pages = {1--1},
publisher = {{Institute of Electrical and Electronics Engineers (IEEE)}},
issn = {2327-4662, 2372-2541},
doi = {10.1109/jiot.2024.3465528},
urldate = {2025-07-23},
copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license
information/IEEE.html},
langid = {english}}

@inproceedings{srinivasansGPSSpoofingDetection2023,
title = {{{GPS Spoofing Detection}} in {{UAV Using Motion Processing Unit}}},
booktitle = {2023 11th {{International Symposium}} on {{Digital Forensics}} and
{{Security}} ({{ISDFS}})},
author = {Srinivasan S, Prasanna and Sathyadevan, Shiju},
year = {2023},
pages = {1--4},
doi = {10.1109/ISDFS58141.2023.10131729},
urldate = {2025-07-23}}

@inproceedings{titounaLightweightSecurityTechnique2021,
title = {A {{Lightweight Security Technique For Unmanned Aerial Vehicles Against
GPS Spoofing Attack}}},
booktitle = {2021 {{International Wireless Communications}} and {{Mobile
Computing}} ({{IWCMC}})},
author = {Titouna, Chafiq and {Na{\"i}t-Abdesselam}, Farid},
year = {2021},
pages = {819--824},
issn = {2376-6506},
doi = {10.1109/IWCMC51323.2021.9498734},
urldate = {2025-07-23}}

@inproceedings{wagnerSecuringCyberPhysicalSystems2023,
title = {Securing {{Cyber-Physical Systems Against GPS Spoofing Attacks Using
Confidence Attribution}}},
booktitle = {2023 {{International Conference}} on {{Software}},
{{Telecommunications}} and {{Computer Networks}} ({{SoftCOM}})},
author = {Wagner, Matheus and Fr{\"o}hlich, Ant{\^o}nio Augusto},
year = {2023},
pages = {1--6},
issn = {1847-358X},
doi = {10.23919/SoftCOM58365.2023.10271629},
urldate = {2025-07-23}}

@misc{aissou2022dataset,
  author       = {Aissou, Ghilas},
  title        = {{A DATASET for GPS Spoofing Detection on Unmanned Aerial System}},
  year         = {2022},
  howpublished = {Mendeley Data, V3},
  doi          = {10.17632/z7dj3yyzt8.3}}

@techreport{dialogos,
    author = "Dialogos Uniao Europeia Brasil",
    title = "Estudo sobre a Indústria Brasileira e Europeia de Veículos aéreos não tripulados",
    institution = "Dialogos Uniao Europeia Brasil",
    year = 2025,
    doi = "https://www.gov.br/mdic/pt-br/images/publicacaoa_DRONES-20161130-20012017-web.pdf",
}

@article{khan,
    author = { Amina Khan and Sumeet Gupta and Sachin Kumar Gupt },
    title = "Emerging UAV technology for disaster detection, mitigation, response, and preparedness",
    journal = "Journal of fields robotics",
    year = 2022,
}

@article{lester,
    author = { Lester de A. Faria1
and Caio A. de Melo Silvestre1
and Marcelino A. Feitosa Correia1
and Nelson A. Roso },
    title = "GPS Jamming Signals Propagation in Free-Space, Urban and Suburban Environments",
    journal = "Journal Aerospacial Tecnology Managment",
    year = 2018,
    page = 10,
    doi = {10.5028/jatm.v10.870}}
@misc{GPSGOV,
  author = {GPS},
  title = {Information for Policymakers from the National Coordination Office
for Space-Based Positioning, Navigation, and Timing (PNT) },
  howpublished = {Global Positioning System Tracker},
  year = {2025},
  url = {https://www.gps.gov/congress/newsletter/2012/10.pdf},
  urldate = {2025-07-23}}
@article{Spoofing,
  author = {Jafarnia-Jahromi, Ali and Broumandan, Ali and  Nielsen, J.and Lachapelle, Gérard},
  title = {GPS Vulnerability to Spoofing Threats and a Review of Antispoofing Techniques},
  journal = {International Journal of Navigation and Observation},
  year = {2012},
  doi = {10.1155/2012/127072}}

@inproceedings{panice2017,
  author={Panice, G. and Luongo, S. and Gigante, G. and Pascarella, D. and Di Benedetto, C. and Vozella, A. and Pescap\è, A.},
  booktitle={2017 23rd International Conference on Automation and Computing (ICAC)}, 
  title={A SVM-based detection approach for GPS spoofing attacks to UAV}, 
  year={2017},
  volume={},
  number={},
  pages={1-11},
  keywords={Global Positioning System;Unmanned aerial vehicles;Aircraft;Sensors;Security;Payloads;Accelerometers;RPAS;UAV;GPS spoofing;Cyber attack;Security},
  doi={10.23919/IConAC.2017.8081999}}

@misc{IBM02025,
  author  = {IBM},
  title   = {What is principal component analysis (PCA)? },
  year    = {2025},
  url     = {https://www.ibm.com/think/topics/principal-component-analysis},
  urldate = {2025-07-31}}

@article{cnn2023,
author = {Sun, Yichen and Yu, Mingxin and Wang, Luyang and Li, Tianfang and
Dong, Mingli},
title = {A Deep-Learning-Based GPS Signal Spoofing Detection Method for Small
UAVs},
journal = {Drones},
volume = {7},
year = {2023},
number = {6},
article-number = {370},
url = {https://www.mdpi.com/2504-446X/7/6/370},
issn = {2504-446X},
doi = {10.3390/drones7060370}}

@article{geurtsExtremelyRandomizedTrees2006,
  title = {Extremely Randomized Trees},
  author = {Geurts, Pierre and Ernst, Damien and Wehenkel, Louis},
  date = {2006},
  journaltitle = {Machine Learning},
  shortjournal = {Mach Learn},
  volume = {63},
  number = {1},
  pages = {3--42},
  issn = {0885-6125, 1573-0565},
  doi = {10.1007/s10994-006-6226-1},
  url = {http://link.springer.com/10.1007/s10994-006-6226-1},
  urldate = {2025-08-06}}

@article{Zhang2019MachineLW,
  title={Machine Learning With Feature Selection Using Principal Component Analysis for Malware Detection: A Case Study},
  author={Jason Y. Zhang},
  journal={ArXiv},
  year={2019},
  volume={abs/1902.03639},
  url={https://api.semanticscholar.org/CorpusID:60440676}}

@article{DEAMORIM2023109924,
  title = {The choice of scaling technique matters for classification performance},
  journal = {Applied Soft Computing},
  volume = {133},
  pages = {109924},
  year = {2023},
  issn = {1568-4946},
  doi = {https://doi.org/10.1016/j.asoc.2022.109924},
  url = {https://www.sciencedirect.com/science/article/pii/S1568494622009735},
  author = {Lucas B.V. {de Amorim} and George D.C. Cavalcanti and Rafael M.O. Cruz},
  keywords = {Classification, Normalization, Standardization, Scaling, Preprocessing, Ensemble of classifiers, Multiple Classifier System},
  abstract = {Dataset scaling, also known as normalization, is an essential preprocessing step in a machine learning pipeline. It is aimed at adjusting attributes scales in a way that they all vary within the same range. This transformation is known to improve the performance of classification models, but there are several scaling techniques to choose from, and this choice is not generally done carefully. In this paper, we execute a broad experiment comparing the impact of 5 scaling techniques on the performances of 20 classification algorithms among monolithic and ensemble models, applying them to 82 publicly available datasets with varying imbalance ratios. Results show that the choice of scaling technique matters for classification performance, and the performance difference between the best and the worst scaling technique is relevant and statistically significant in most cases. They also indicate that choosing an inadequate technique can be more detrimental to classification performance than not scaling the data at all. We also show how the performance variation of an ensemble model, considering different scaling techniques, tends to be dictated by that of its base model. Finally, we discuss the relationship between a model’s sensitivity to the choice of scaling technique and its performance and provide insights into its applicability on different model deployment scenarios. Full results and source code for the experiments in this paper are available in a GitHub repository.11https://github.com/amorimlb/scaling_matters.}}

@Article{electronics13101878,
  AUTHOR = {Fan, Zongwen and Sohail, Shaleeza and Sabrina, Fariza and Gu, Xin},
  TITLE = {Sampling-Based Machine Learning Models for Intrusion Detection in Imbalanced Dataset},
  JOURNAL = {Electronics},
  VOLUME = {13},
  YEAR = {2024},
  NUMBER = {10},
  ARTICLE-NUMBER = {1878},
  URL = {https://www.mdpi.com/2079-9292/13/10/1878},
  ISSN = {2079-9292},
  ABSTRACT = {Cybersecurity is one of the important considerations when adopting IoT devices in smart applications. Even though a huge volume of data is available, data related to attacks are generally in a significantly smaller proportion. Although machine learning models have been successfully applied for detecting security attacks on smart applications, their performance is affected by the problem of such data imbalance. In this case, the prediction model is preferable to the majority class, while the performance for predicting the minority class is poor. To address such problems, we apply two oversampling techniques and two undersampling techniques to balance the data in different categories. To verify their performance, five machine learning models, namely the decision tree, multi-layer perception, random forest, XGBoost, and CatBoost, are used in the experiments based on the grid search with 10-fold cross-validation for parameter tuning. The results show that both the oversampling and undersampling techniques can improve the performance of the prediction models used. Based on the results, the XGBoost model based on the SMOTE has the best performance in terms of accuracy at 75%, weighted average precision at 82%, weighted average recall at 75%, weighted average F1 score at 78%, and Matthews correlation coefficient at 72%. This indicates that this oversampling technique is effective for multi-attack prediction under a data imbalance scenario.},
  DOI = {10.3390/electronics13101878}}

@article{MCC,
  doi = {10.1371/journal.pone.0041882},
  author = {Jurman, Giuseppe AND Riccadonna, Samantha AND Furlanello,
  Cesare},
  journal = {PLOS ONE},
  publisher = {Public Library of Science},
  title = {A Comparison of MCC and CEN Error Measures in Multi-Class
  Prediction},
  year = {2012},
  volume = {7},
  url = {https://doi.org/10.1371/journal.pone.0041882},
  pages = {1-8},
  abstract = {We show that the Confusion Entropy, a measure of performance
  in multiclass problems has a strong (monotone) relation with the multiclass
  generalization of a classical metric, the Matthews Correlation Coefficient.
  Analytical results are provided for the limit cases of general no-information (n
  face dice rolling) of the binary classification. Computational evidence supports
  the claim in the general case.},
  number = {8}}

@article{Haghighi2018,
  doi = {10.21105/joss.00729},
  url = {https://doi.org/10.21105/joss.00729},
  year  = {2018},
  publisher = {The Open Journal},
  volume = {3},
  number = {25},
  pages = {729},
  author = {Sepand Haghighi and Masoomeh Jasemi and Shaahin Hessabi and Alireza Zolanvari},
  title = {{PyCM}: Multiclass confusion matrix library in Python},
  journal = {Journal of Open Source Software}}

@article{pearson1901,
  author    = {Karl Pearson},
  title     = {On Lines and Planes of Closest Fit to Systems of Points in Space},
  journal   = {The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science},
  volume    = {2},
  number    = {11},
  pages     = {559--572},
  year      = {1901},
  doi       = {10.1080/14786440109462720}}

@inproceedings{japkowicz2000,
  author    = {Nathalie Japkowicz},
  title     = {Learning from Imbalanced Data Sets},
  booktitle = {Proceedings of the AAAI Workshop on Learning from Imbalanced Data Sets},
  year      = {2000},
  publisher = {AAAI Press}}

@article{pearson1894,
  author    = {Karl Pearson},
  title     = {Contributions to the Mathematical Theory of Evolution},
  journal   = {Philosophical Transactions of the Royal Society of London. A},
  volume    = {185},
  pages     = {71--110},
  year      = {1894},
  doi       = {10.1098/rsta.1894.0003},
  publisher = {Royal Society}}

@article{Zhang2019MachineLW,
  title={Machine Learning With Feature Selection Using Principal Component Analysis for Malware Detection: A Case Study},
  author={Jason Y. Zhang},
  journal={ArXiv},
  year={2019},
  volume={abs/1902.03639},
  url={https://api.semanticscholar.org/CorpusID:60440676}}

@article{DEAMORIM2023109924,
  title = {The choice of scaling technique matters for classification performance},
  journal = {Applied Soft Computing},
  volume = {133},
  pages = {109924},
  year = {2023},
  issn = {1568-4946},
  doi = {https://doi.org/10.1016/j.asoc.2022.109924},
  url = {https://www.sciencedirect.com/science/article/pii/S1568494622009735},
  author = {Lucas B.V. {de Amorim} and George D.C. Cavalcanti and Rafael M.O. Cruz},
  keywords = {Classification, Normalization, Standardization, Scaling, Preprocessing, Ensemble of classifiers, Multiple Classifier System},
  abstract = {Dataset scaling, also known as normalization, is an essential preprocessing step in a machine learning pipeline. It is aimed at adjusting attributes scales in a way that they all vary within the same range. This transformation is known to improve the performance of classification models, but there are several scaling techniques to choose from, and this choice is not generally done carefully. In this paper, we execute a broad experiment comparing the impact of 5 scaling techniques on the performances of 20 classification algorithms among monolithic and ensemble models, applying them to 82 publicly available datasets with varying imbalance ratios. Results show that the choice of scaling technique matters for classification performance, and the performance difference between the best and the worst scaling technique is relevant and statistically significant in most cases. They also indicate that choosing an inadequate technique can be more detrimental to classification performance than not scaling the data at all. We also show how the performance variation of an ensemble model, considering different scaling techniques, tends to be dictated by that of its base model. Finally, we discuss the relationship between a model’s sensitivity to the choice of scaling technique and its performance and provide insights into its applicability on different model deployment scenarios. Full results and source code for the experiments in this paper are available in a GitHub repository.11https://github.com/amorimlb/scaling_matters.}}

@Article{electronics13101878,
  AUTHOR = {Fan, Zongwen and Sohail, Shaleeza and Sabrina, Fariza and Gu, Xin},
  TITLE = {Sampling-Based Machine Learning Models for Intrusion Detection in Imbalanced Dataset},
  JOURNAL = {Electronics},
  VOLUME = {13},
  YEAR = {2024},
  NUMBER = {10},
  ARTICLE-NUMBER = {1878},
  URL = {https://www.mdpi.com/2079-9292/13/10/1878},
  ISSN = {2079-9292},
  ABSTRACT = {Cybersecurity is one of the important considerations when adopting IoT devices in smart applications. Even though a huge volume of data is available, data related to attacks are generally in a significantly smaller proportion. Although machine learning models have been successfully applied for detecting security attacks on smart applications, their performance is affected by the problem of such data imbalance. In this case, the prediction model is preferable to the majority class, while the performance for predicting the minority class is poor. To address such problems, we apply two oversampling techniques and two undersampling techniques to balance the data in different categories. To verify their performance, five machine learning models, namely the decision tree, multi-layer perception, random forest, XGBoost, and CatBoost, are used in the experiments based on the grid search with 10-fold cross-validation for parameter tuning. The results show that both the oversampling and undersampling techniques can improve the performance of the prediction models used. Based on the results, the XGBoost model based on the SMOTE has the best performance in terms of accuracy at 75%, weighted average precision at 82%, weighted average recall at 75%, weighted average F1 score at 78%, and Matthews correlation coefficient at 72%. This indicates that this oversampling technique is effective for multi-attack prediction under a data imbalance scenario.},
  DOI = {10.3390/electronics13101878}}

@article{pearson1901,
  author    = {Karl Pearson},
  title     = {On Lines and Planes of Closest Fit to Systems of Points in Space},
  journal   = {The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science},
  volume    = {2},
  number    = {11},
  pages     = {559--572},
  year      = {1901},
  doi       = {10.1080/14786440109462720}}

@inproceedings{japkowicz2000,
  author    = {Nathalie Japkowicz},
  title     = {Learning from Imbalanced Data Sets},
  booktitle = {Proceedings of the AAAI Workshop on Learning from Imbalanced Data Sets},
  year      = {2000},
  publisher = {AAAI Press}}

@article{pearson1901,
  author    = {Karl Pearson},
  title     = {On Lines and Planes of Closest Fit to Systems of Points in Space},
  journal   = {The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science},
  volume    = {2},
  number    = {11},
  pages     = {559--572},
  year      = {1901},
  doi       = {10.1080/14786440109462720}}

@inproceedings{japkowicz2000,
  author    = {Nathalie Japkowicz},
  title     = {Learning from Imbalanced Data Sets},
  booktitle = {Proceedings of the AAAI Workshop on Learning from Imbalanced Data Sets},
  year      = {2000},
  publisher = {AAAI Press}}

@article{pearson1894,
  author    = {Karl Pearson},
  title     = {Contributions to the Mathematical Theory of Evolution},
  journal   = {Philosophical Transactions of the Royal Society of London. A},
  volume    = {185},
  pages     = {71--110},
  year      = {1894},
  doi       = {10.1098/rsta.1894.0003},
  publisher = {Royal Society}
}
